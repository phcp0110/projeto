{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63da49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmol.loaders import CSVLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from CSV file\n",
    "loader = CSVLoader(dataset_path='amostras_30000.csv',\n",
    "                   smiles_field='smiles',\n",
    "                   id_field='ids',\n",
    "                   mode='auto')\n",
    "# create the dataset\n",
    "csv_dataset = loader.create_dataset(sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1260ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"integrated_dataset.csv\")\n",
    "amostras = df.sample(n=30000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301b6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "amostras.to_csv(\"amostras_30000.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647c694",
   "metadata": {},
   "source": [
    "# NP Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d55300f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "2025-05-08 14:31:07.232147: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-08 14:31:07.278455: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-08 14:31:07.278510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-08 14:31:07.279955: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-08 14:31:07.287814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-08 14:31:08.155127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ppereira/miniforge3/envs/Project/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/home/ppereira/miniforge3/envs/Project/lib/python3.11/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "NPClassifierFP: 100%|██████████| 30000/30000 [00:45<00:00, 661.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from deepmol.compound_featurization import NPClassifierFP\n",
    "\n",
    "NPClassifierFP(n_jobs=10).featurize(csv_dataset, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c532ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 6144)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dbc8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd36fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.,  3.,  4., 36., 42., 50.]),\n",
       " array([6111,   10,   11,    8,    1,    1,    1,    1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(csv_dataset.X[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fe2d3",
   "metadata": {},
   "source": [
    "# Biosynfoni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "265732e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BiosynfoniKeys: 100%|██████████| 30000/30000 [00:23<00:00, 1263.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from deepmol.compound_featurization import BiosynfoniKeys\n",
    "\n",
    "BiosynfoniKeys(n_jobs=10).featurize(csv_dataset, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97661b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75934fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1., 10.,  5., 55.,  4.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc51718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  4.,  5., 10., 55.]), array([34,  1,  1,  1,  1,  1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(csv_dataset.X[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f690e",
   "metadata": {},
   "source": [
    "# Neural NPFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f2dafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppereira/miniforge3/envs/Project/lib/python3.11/site-packages/deepmol/compound_featurization/neural_npfp_generator.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(FILE_PATH, \"neural_npfp\", \"aux_cv0.pt\"), map_location=torch.device(\"cpu\")))\n",
      "NeuralNPFP:   0%|          | 0/30000 [00:00<?, ?it/s]/home/ppereira/miniforge3/envs/Project/lib/python3.11/site-packages/deepmol/compound_featurization/neural_npfp_generator.py:82: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  fp = torch.tensor([fp], dtype=torch.float)\n",
      "NeuralNPFP: 100%|██████████| 30000/30000 [01:35<00:00, 313.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from deepmol.compound_featurization import NeuralNPFP\n",
    "\n",
    "NeuralNPFP(n_jobs=10).featurize(csv_dataset, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac25c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "391b200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.82657611, -0.14013769, -1.78766513,  1.81063437, -2.32493448,\n",
       "       -2.39600992,  1.84732926,  2.36158395, -1.78433383, -0.46329024,\n",
       "        2.15387702, -0.40001643, -1.59564078, -2.06041574,  1.44741619,\n",
       "       -2.21173239, -0.61478484,  1.85280526,  0.45151985, -1.71923113,\n",
       "       -2.32591343, -2.22309494, -2.22470307,  1.64728463, -1.65957129,\n",
       "       -1.75095212, -2.07849526,  1.21179235,  2.7078526 , -1.06124187,\n",
       "        2.59967804, -1.30787718,  1.64624715, -2.55019975,  2.57820582,\n",
       "       -2.15027928, -1.2620945 , -0.98375863,  0.73135829,  1.08484197,\n",
       "        2.8657856 , -2.6965363 ,  1.04068708,  1.42691851,  1.0653019 ,\n",
       "        1.80034328, -0.1244522 , -1.30602562,  1.14200723,  1.62013364,\n",
       "       -1.81430066,  1.48497033, -1.31255066,  1.84707391,  2.05637836,\n",
       "        0.90538549,  0.05679986, -2.15124702, -1.85069108, -1.70023704,\n",
       "       -2.08359456,  1.49881494, -2.43924689,  1.41526985])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6024589a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-2.6965363 , -2.55019975, -2.43924689, -2.39600992, -2.32591343,\n",
       "        -2.32493448, -2.22470307, -2.22309494, -2.21173239, -2.15124702,\n",
       "        -2.15027928, -2.08359456, -2.07849526, -2.06041574, -1.85069108,\n",
       "        -1.81430066, -1.78766513, -1.78433383, -1.75095212, -1.71923113,\n",
       "        -1.70023704, -1.65957129, -1.59564078, -1.31255066, -1.30787718,\n",
       "        -1.30602562, -1.2620945 , -1.06124187, -0.98375863, -0.61478484,\n",
       "        -0.46329024, -0.40001643, -0.14013769, -0.1244522 ,  0.05679986,\n",
       "         0.45151985,  0.73135829,  0.90538549,  1.04068708,  1.0653019 ,\n",
       "         1.08484197,  1.14200723,  1.21179235,  1.41526985,  1.42691851,\n",
       "         1.44741619,  1.48497033,  1.49881494,  1.62013364,  1.64624715,\n",
       "         1.64728463,  1.80034328,  1.81063437,  1.82657611,  1.84707391,\n",
       "         1.84732926,  1.85280526,  2.05637836,  2.15387702,  2.36158395,\n",
       "         2.57820582,  2.59967804,  2.7078526 ,  2.8657856 ]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(csv_dataset.X[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c01ad",
   "metadata": {},
   "source": [
    "# MHFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c160af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmol.compound_featurization import MHFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61bfefd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96c7da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.82657611, -0.14013769, -1.78766513,  1.81063437, -2.32493448,\n",
       "       -2.39600992,  1.84732926,  2.36158395, -1.78433383, -0.46329024,\n",
       "        2.15387702, -0.40001643, -1.59564078, -2.06041574,  1.44741619,\n",
       "       -2.21173239, -0.61478484,  1.85280526,  0.45151985, -1.71923113,\n",
       "       -2.32591343, -2.22309494, -2.22470307,  1.64728463, -1.65957129,\n",
       "       -1.75095212, -2.07849526,  1.21179235,  2.7078526 , -1.06124187,\n",
       "        2.59967804, -1.30787718,  1.64624715, -2.55019975,  2.57820582,\n",
       "       -2.15027928, -1.2620945 , -0.98375863,  0.73135829,  1.08484197,\n",
       "        2.8657856 , -2.6965363 ,  1.04068708,  1.42691851,  1.0653019 ,\n",
       "        1.80034328, -0.1244522 , -1.30602562,  1.14200723,  1.62013364,\n",
       "       -1.81430066,  1.48497033, -1.31255066,  1.84707391,  2.05637836,\n",
       "        0.90538549,  0.05679986, -2.15124702, -1.85069108, -1.70023704,\n",
       "       -2.08359456,  1.49881494, -2.43924689,  1.41526985])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73dd51dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SmilesDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m np.unique(\u001b[43mcsv_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, return_counts=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: 'SmilesDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "np.unique(csv_dataset[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a6aa28",
   "metadata": {},
   "source": [
    "# Morgan Fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MorganFingerprint: 100%|██████████| 30000/30000 [01:00<00:00, 493.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from deepmol.compound_featurization import  MorganFingerprint\n",
    "\n",
    "MorganFingerprint(n_jobs=10).featurize(csv_dataset, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233faf57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2048)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687af43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([2015,   33]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(csv_dataset.X[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "129ab6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def manhattan_similarity(x, y, method='normalized', lambda_=1.0):\n",
    "    \"\"\"\n",
    "    Compute Manhattan similarity between two vectors.\n",
    "    Parameters:\n",
    "        x, y : array-like\n",
    "            Input vectors (must be the same length).\n",
    "        method : str\n",
    "            'normalized' for linear similarity in [0, 1],\n",
    "            'exponential' for exp(-lambda * distance).\n",
    "        lambda_ : float\n",
    "            Used only in 'exponential' method as scaling factor.\n",
    "    Returns:\n",
    "        float : Similarity score.\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    " \n",
    "    distance = np.sum(np.abs(x - y))\n",
    " \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af587cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_dataset.X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a189d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "434888b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.9339318163693"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_similarity(csv_dataset.X[0],csv_dataset.X[6567])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3749f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NPClassifierFP: 100%|██████████| 30000/30000 [00:45<00:00, 654.89it/s]\n",
      "BiosynfoniKeys: 100%|██████████| 30000/30000 [00:22<00:00, 1308.65it/s]\n"
     ]
    }
   ],
   "source": [
    "NPClassifierFP(n_jobs=10).featurize(csv_dataset, inplace=True)\n",
    "BiosynfoniKeys(n_jobs=10).featurize(csv_dataset, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cf2989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppereira/miniforge3/envs/Project/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2361: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# 1 - matriz de similaridade Tanimoto\n",
    "similarity = 1 - pairwise_distances(csv_dataset.X, metric='jaccard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6a654b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 0.28571429, 0.5       , 0.5       ,\n",
       "        0.17647059, 0.35714286, 0.26666667, 0.45454545, 0.41666667,\n",
       "        0.83333333, 1.        , 0.33333333, 0.55555556, 0.71428571,\n",
       "        0.83333333, 0.4       , 0.625     , 0.28571429, 0.5       ,\n",
       "        0.83333333, 0.55555556, 0.55555556, 0.36363636, 0.71428571],\n",
       "       [1.        , 1.        , 0.28571429, 0.5       , 0.5       ,\n",
       "        0.17647059, 0.35714286, 0.26666667, 0.45454545, 0.41666667,\n",
       "        0.83333333, 1.        , 0.33333333, 0.55555556, 0.71428571,\n",
       "        0.83333333, 0.4       , 0.625     , 0.28571429, 0.5       ,\n",
       "        0.83333333, 0.55555556, 0.55555556, 0.36363636, 0.71428571],\n",
       "       [0.28571429, 0.28571429, 1.        , 0.16666667, 0.16666667,\n",
       "        0.1875    , 0.2       , 0.125     , 0.25      , 0.23076923,\n",
       "        0.25      , 0.28571429, 0.1875    , 0.18181818, 0.22222222,\n",
       "        0.42857143, 0.3       , 0.33333333, 0.21428571, 0.27272727,\n",
       "        0.42857143, 0.3       , 0.3       , 0.16666667, 0.375     ],\n",
       "       [0.5       , 0.5       , 0.16666667, 1.        , 0.42857143,\n",
       "        0.38888889, 0.33333333, 0.6       , 0.3125    , 0.375     ,\n",
       "        0.6       , 0.5       , 0.31578947, 0.46153846, 0.54545455,\n",
       "        0.45454545, 0.26666667, 0.38461538, 0.53333333, 0.53846154,\n",
       "        0.45454545, 0.46153846, 0.46153846, 0.66666667, 0.54545455],\n",
       "       [0.5       , 0.5       , 0.16666667, 0.42857143, 1.        ,\n",
       "        0.31578947, 0.33333333, 0.5       , 0.3125    , 0.375     ,\n",
       "        0.6       , 0.5       , 0.31578947, 0.46153846, 0.54545455,\n",
       "        0.45454545, 0.26666667, 0.5       , 0.27777778, 0.42857143,\n",
       "        0.45454545, 0.46153846, 0.58333333, 0.33333333, 0.54545455],\n",
       "       [0.17647059, 0.17647059, 0.1875    , 0.38888889, 0.31578947,\n",
       "        1.        , 0.52631579, 0.52631579, 0.52941176, 0.5       ,\n",
       "        0.23529412, 0.17647059, 0.5       , 0.26315789, 0.22222222,\n",
       "        0.23529412, 0.41176471, 0.21052632, 0.75      , 0.47058824,\n",
       "        0.23529412, 0.26315789, 0.33333333, 0.47058824, 0.29411765],\n",
       "       [0.35714286, 0.35714286, 0.2       , 0.33333333, 0.33333333,\n",
       "        0.52631579, 1.        , 0.27272727, 0.78571429, 0.85714286,\n",
       "        0.42857143, 0.35714286, 0.93333333, 0.64285714, 0.5       ,\n",
       "        0.42857143, 0.64285714, 0.375     , 0.58823529, 0.6       ,\n",
       "        0.42857143, 0.4375    , 0.53333333, 0.33333333, 0.5       ],\n",
       "       [0.26666667, 0.26666667, 0.125     , 0.6       , 0.5       ,\n",
       "        0.52631579, 0.27272727, 1.        , 0.25      , 0.3       ,\n",
       "        0.33333333, 0.26666667, 0.26086957, 0.27777778, 0.3125    ,\n",
       "        0.25      , 0.21052632, 0.22222222, 0.5       , 0.41176471,\n",
       "        0.25      , 0.27777778, 0.27777778, 0.71428571, 0.3125    ],\n",
       "       [0.45454545, 0.45454545, 0.25      , 0.3125    , 0.3125    ,\n",
       "        0.52941176, 0.78571429, 0.25      , 1.        , 0.76923077,\n",
       "        0.41666667, 0.45454545, 0.73333333, 0.42857143, 0.38461538,\n",
       "        0.54545455, 0.81818182, 0.46153846, 0.6       , 0.61538462,\n",
       "        0.54545455, 0.42857143, 0.53846154, 0.3125    , 0.5       ],\n",
       "       [0.41666667, 0.41666667, 0.23076923, 0.375     , 0.375     ,\n",
       "        0.5       , 0.85714286, 0.3       , 0.76923077, 1.        ,\n",
       "        0.5       , 0.41666667, 0.8       , 0.5       , 0.58333333,\n",
       "        0.5       , 0.75      , 0.42857143, 0.66666667, 0.57142857,\n",
       "        0.5       , 0.5       , 0.5       , 0.375     , 0.58333333],\n",
       "       [0.83333333, 0.83333333, 0.25      , 0.6       , 0.6       ,\n",
       "        0.23529412, 0.42857143, 0.33333333, 0.41666667, 0.5       ,\n",
       "        1.        , 0.83333333, 0.4       , 0.66666667, 0.85714286,\n",
       "        0.71428571, 0.36363636, 0.55555556, 0.35714286, 0.6       ,\n",
       "        0.71428571, 0.66666667, 0.66666667, 0.45454545, 0.85714286],\n",
       "       [1.        , 1.        , 0.28571429, 0.5       , 0.5       ,\n",
       "        0.17647059, 0.35714286, 0.26666667, 0.45454545, 0.41666667,\n",
       "        0.83333333, 1.        , 0.33333333, 0.55555556, 0.71428571,\n",
       "        0.83333333, 0.4       , 0.625     , 0.28571429, 0.5       ,\n",
       "        0.83333333, 0.55555556, 0.55555556, 0.36363636, 0.71428571],\n",
       "       [0.33333333, 0.33333333, 0.1875    , 0.31578947, 0.31578947,\n",
       "        0.5       , 0.93333333, 0.26086957, 0.73333333, 0.8       ,\n",
       "        0.4       , 0.33333333, 1.        , 0.6       , 0.46666667,\n",
       "        0.4       , 0.6       , 0.35294118, 0.55555556, 0.5625    ,\n",
       "        0.4       , 0.41176471, 0.5       , 0.31578947, 0.46666667],\n",
       "       [0.55555556, 0.55555556, 0.18181818, 0.46153846, 0.46153846,\n",
       "        0.26315789, 0.64285714, 0.27777778, 0.42857143, 0.5       ,\n",
       "        0.66666667, 0.55555556, 0.6       , 1.        , 0.77777778,\n",
       "        0.5       , 0.28571429, 0.41666667, 0.29411765, 0.58333333,\n",
       "        0.5       , 0.5       , 0.63636364, 0.35714286, 0.6       ],\n",
       "       [0.71428571, 0.71428571, 0.22222222, 0.54545455, 0.54545455,\n",
       "        0.22222222, 0.5       , 0.3125    , 0.38461538, 0.58333333,\n",
       "        0.85714286, 0.71428571, 0.46666667, 0.77777778, 1.        ,\n",
       "        0.625     , 0.33333333, 0.5       , 0.33333333, 0.54545455,\n",
       "        0.625     , 0.6       , 0.6       , 0.41666667, 0.75      ],\n",
       "       [0.83333333, 0.83333333, 0.42857143, 0.45454545, 0.45454545,\n",
       "        0.23529412, 0.42857143, 0.25      , 0.54545455, 0.5       ,\n",
       "        0.71428571, 0.83333333, 0.4       , 0.5       , 0.625     ,\n",
       "        1.        , 0.5       , 0.75      , 0.35714286, 0.6       ,\n",
       "        1.        , 0.66666667, 0.66666667, 0.33333333, 0.85714286],\n",
       "       [0.4       , 0.4       , 0.3       , 0.26666667, 0.26666667,\n",
       "        0.41176471, 0.64285714, 0.21052632, 0.81818182, 0.75      ,\n",
       "        0.36363636, 0.4       , 0.6       , 0.28571429, 0.33333333,\n",
       "        0.5       , 1.        , 0.41666667, 0.57142857, 0.46153846,\n",
       "        0.5       , 0.38461538, 0.38461538, 0.26666667, 0.45454545],\n",
       "       [0.625     , 0.625     , 0.33333333, 0.38461538, 0.5       ,\n",
       "        0.21052632, 0.375     , 0.22222222, 0.46153846, 0.42857143,\n",
       "        0.55555556, 0.625     , 0.35294118, 0.41666667, 0.5       ,\n",
       "        0.75      , 0.41666667, 1.        , 0.3125    , 0.5       ,\n",
       "        0.75      , 0.54545455, 0.7       , 0.28571429, 0.66666667],\n",
       "       [0.28571429, 0.28571429, 0.21428571, 0.53333333, 0.27777778,\n",
       "        0.75      , 0.58823529, 0.5       , 0.6       , 0.66666667,\n",
       "        0.35714286, 0.28571429, 0.55555556, 0.29411765, 0.33333333,\n",
       "        0.35714286, 0.57142857, 0.3125    , 1.        , 0.53333333,\n",
       "        0.35714286, 0.375     , 0.375     , 0.64285714, 0.42857143],\n",
       "       [0.5       , 0.5       , 0.27272727, 0.53846154, 0.42857143,\n",
       "        0.47058824, 0.6       , 0.41176471, 0.61538462, 0.57142857,\n",
       "        0.6       , 0.5       , 0.5625    , 0.58333333, 0.54545455,\n",
       "        0.6       , 0.46153846, 0.5       , 0.53333333, 1.        ,\n",
       "        0.6       , 0.58333333, 0.72727273, 0.53846154, 0.7       ],\n",
       "       [0.83333333, 0.83333333, 0.42857143, 0.45454545, 0.45454545,\n",
       "        0.23529412, 0.42857143, 0.25      , 0.54545455, 0.5       ,\n",
       "        0.71428571, 0.83333333, 0.4       , 0.5       , 0.625     ,\n",
       "        1.        , 0.5       , 0.75      , 0.35714286, 0.6       ,\n",
       "        1.        , 0.66666667, 0.66666667, 0.33333333, 0.85714286],\n",
       "       [0.55555556, 0.55555556, 0.3       , 0.46153846, 0.46153846,\n",
       "        0.26315789, 0.4375    , 0.27777778, 0.42857143, 0.5       ,\n",
       "        0.66666667, 0.55555556, 0.41176471, 0.5       , 0.6       ,\n",
       "        0.66666667, 0.38461538, 0.54545455, 0.375     , 0.58333333,\n",
       "        0.66666667, 1.        , 0.63636364, 0.35714286, 0.77777778],\n",
       "       [0.55555556, 0.55555556, 0.3       , 0.46153846, 0.58333333,\n",
       "        0.33333333, 0.53333333, 0.27777778, 0.53846154, 0.5       ,\n",
       "        0.66666667, 0.55555556, 0.5       , 0.63636364, 0.6       ,\n",
       "        0.66666667, 0.38461538, 0.7       , 0.375     , 0.72727273,\n",
       "        0.66666667, 0.63636364, 1.        , 0.35714286, 0.77777778],\n",
       "       [0.36363636, 0.36363636, 0.16666667, 0.66666667, 0.33333333,\n",
       "        0.47058824, 0.33333333, 0.71428571, 0.3125    , 0.375     ,\n",
       "        0.45454545, 0.36363636, 0.31578947, 0.35714286, 0.41666667,\n",
       "        0.33333333, 0.26666667, 0.28571429, 0.64285714, 0.53846154,\n",
       "        0.33333333, 0.35714286, 0.35714286, 1.        , 0.41666667],\n",
       "       [0.71428571, 0.71428571, 0.375     , 0.54545455, 0.54545455,\n",
       "        0.29411765, 0.5       , 0.3125    , 0.5       , 0.58333333,\n",
       "        0.85714286, 0.71428571, 0.46666667, 0.6       , 0.75      ,\n",
       "        0.85714286, 0.45454545, 0.66666667, 0.42857143, 0.7       ,\n",
       "        0.85714286, 0.77777778, 0.77777778, 0.41666667, 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[:25, :25]  # Mostra o canto superior esquerdo da matriz (5x5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19dfb231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29990</th>\n",
       "      <th>29991</th>\n",
       "      <th>29992</th>\n",
       "      <th>29993</th>\n",
       "      <th>29994</th>\n",
       "      <th>29995</th>\n",
       "      <th>29996</th>\n",
       "      <th>29997</th>\n",
       "      <th>29998</th>\n",
       "      <th>29999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 30000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6       \n",
       "0      1.000000  1.000000  0.285714  0.500000  0.500000  0.176471  0.357143  \\\n",
       "1      1.000000  1.000000  0.285714  0.500000  0.500000  0.176471  0.357143   \n",
       "2      0.285714  0.285714  1.000000  0.166667  0.166667  0.187500  0.200000   \n",
       "3      0.500000  0.500000  0.166667  1.000000  0.428571  0.388889  0.333333   \n",
       "4      0.500000  0.500000  0.166667  0.428571  1.000000  0.315789  0.333333   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  0.454545  0.454545  0.250000  0.400000  0.400000  0.368421  0.785714   \n",
       "29996  0.363636  0.363636  0.272727  0.428571  0.428571  0.470588  0.411765   \n",
       "29997  0.800000  0.800000  0.142857  0.400000  0.400000  0.117647  0.285714   \n",
       "29998  0.666667  0.666667  0.285714  0.363636  0.363636  0.176471  0.357143   \n",
       "29999  0.500000  0.500000  0.222222  0.416667  0.416667  0.294118  0.400000   \n",
       "\n",
       "          7         8         9      ...     29990     29991     29992   \n",
       "0      0.266667  0.454545  0.416667  ...  0.571429  0.400000  0.714286  \\\n",
       "1      0.266667  0.454545  0.416667  ...  0.571429  0.400000  0.714286   \n",
       "2      0.125000  0.250000  0.230769  ...  0.250000  0.300000  0.222222   \n",
       "3      0.600000  0.312500  0.375000  ...  0.454545  0.266667  0.700000   \n",
       "4      0.500000  0.312500  0.375000  ...  0.454545  0.266667  0.545455   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "29995  0.315789  0.571429  0.642857  ...  0.545455  0.428571  0.500000   \n",
       "29996  0.600000  0.400000  0.466667  ...  0.600000  0.357143  0.545455   \n",
       "29997  0.200000  0.363636  0.333333  ...  0.428571  0.300000  0.571429   \n",
       "29998  0.266667  0.454545  0.416667  ...  0.571429  0.555556  0.500000   \n",
       "29999  0.500000  0.384615  0.461538  ...  0.857143  0.333333  0.555556   \n",
       "\n",
       "          29993     29994     29995     29996     29997     29998     29999  \n",
       "0      0.500000  0.714286  0.454545  0.363636  0.800000  0.666667  0.500000  \n",
       "1      0.500000  0.714286  0.454545  0.363636  0.800000  0.666667  0.500000  \n",
       "2      0.142857  0.375000  0.250000  0.272727  0.142857  0.285714  0.222222  \n",
       "3      0.272727  0.416667  0.400000  0.428571  0.400000  0.363636  0.416667  \n",
       "4      0.272727  0.416667  0.400000  0.428571  0.400000  0.363636  0.416667  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "29995  0.250000  0.636364  1.000000  0.500000  0.363636  0.454545  0.500000  \n",
       "29996  0.400000  0.416667  0.500000  1.000000  0.272727  0.363636  0.700000  \n",
       "29997  0.600000  0.571429  0.363636  0.272727  1.000000  0.500000  0.375000  \n",
       "29998  0.285714  0.500000  0.454545  0.363636  0.500000  1.000000  0.500000  \n",
       "29999  0.571429  0.400000  0.500000  0.700000  0.375000  0.500000  1.000000  \n",
       "\n",
       "[30000 rows x 30000 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_similarity = pd.DataFrame(similarity)\n",
    "df_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.figure(figsize=(10,8))\n",
    "#sns.heatmap(similarity, cmap='viridis')\n",
    "#plt.title(\"Matriz de Similaridade Tanimoto\")\n",
    "#plt.show()\n",
    "\n",
    "# A matriz é gigante isto não vai sair daqui, vale a pena fazer o heatmap de 300 moleculas ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed54aa1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Converter a matriz de similaridade em distância (assumindo que 'similarity' já está definido)\n",
    "distance_matrix = 1 - similarity\n",
    "\n",
    "# Criar grafo com as distâncias\n",
    "G = nx.from_numpy_array(distance_matrix)\n",
    "\n",
    "# Calcular a Minimum Spanning Tree (MST)\n",
    "mst = nx.minimum_spanning_tree(G)\n",
    "\n",
    "# Verificar número de nós para decidir como desenhar\n",
    "num_nodes = len(mst.nodes)\n",
    "\n",
    "print(f\"MST tem {num_nodes} nós.\")\n",
    "\n",
    "# Visualizar a MST apenas se o grafo for pequeno o suficiente\n",
    "if num_nodes <= 300:\n",
    "    plt.figure(figsize=(15, 12))\n",
    "\n",
    "    # Usar layout mais rápido (kamada_kawai) ou spring com menos iterações\n",
    "    try:\n",
    "        pos = nx.kamada_kawai_layout(mst)\n",
    "    except:\n",
    "        pos = nx.spring_layout(mst, seed=42, iterations=50)\n",
    "\n",
    "    nx.draw(mst, pos,\n",
    "            with_labels=True,\n",
    "            node_size=50,\n",
    "            font_size=8,\n",
    "            edge_color='gray')\n",
    "\n",
    "    plt.title('Minimum Spanning Tree (MST) - Similaridade Tanimoto')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"A visualização foi omitida porque o grafo tem muitos nós.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
